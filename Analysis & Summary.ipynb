{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0cf2521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "\n",
    "metricContainer1 = np.load(\"metric arrays/metrics_original_normal_ttsplit.npz\")          #Array of performance metrics realized from initial attempt using normal train_test_split.\n",
    "metrics_Initial = metricContainer1[\"arr_0\"]\n",
    "\n",
    "metricContainer2 = np.load(\"metric arrays/metrics_TestingCV.npz\")                        #Array of performance metrics realized during plain cross-validation testing.\n",
    "metrics_TestingCV = metricContainer2[\"arr_0\"]\n",
    "\n",
    "metricContainer3 = np.load(\"metric arrays/metrics_ageS6_removed.npz\")                     #Array of performance metrics realized when low importance features were removed.\n",
    "metrics_ageS6_removed = metricContainer3[\"arr_0\"]\n",
    "\n",
    "metricContainer4 = np.load(\"metric arrays/metrics_mod_complete.npz\")                       #Array of performance metrics realized when low importance features have been removed and interaction features added.\n",
    "metrics_mod_complete = metricContainer4[\"arr_0\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d917fbee",
   "metadata": {},
   "source": [
    "Below comparison of metrics will be made. These metrics contained in the arrays above, represent the result of 4 stages of attempts made to model more robustly the sklearn's load_diabetes dataset.\n",
    "\n",
    "1. First attempt: The diabetes dataset was split, modelled and evaluated with 6 models using the basic train_test_split approach.\n",
    "\n",
    "2. Second attempt: Use of cross-validation(CV) across 6 models to get better model performance on the dataset.\n",
    "\n",
    "3. Third attempt: In addition to CV, dropped 2 very low importance features; decision informed through analysis of feature importances and possible interactions. File attached(TestForInteraction.ipynb)\n",
    "\n",
    "4. Fourth attempt: Adding to step 3 above, created 3 new interaction features; interactions determined through analysis of feature interactions. File attached(TestForInteraction.ipynb)\n",
    "\n",
    "Note: Metrics realized from the 2nd attempt using CV (see Testing_CV branch), are used as base line. Comparison is therefore made against it. Metrics realized from subsequent attempts are subtracted from baseline. Data is displayed in tables for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "011e512d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OLSRegression</th>\n",
       "      <th>LassoRegression</th>\n",
       "      <th>RidgeRegression</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>NeuralNetwok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MSE score</th>\n",
       "      <td>3145.386692</td>\n",
       "      <td>4067.208772</td>\n",
       "      <td>3712.537141</td>\n",
       "      <td>3115.877072</td>\n",
       "      <td>3461.812012</td>\n",
       "      <td>22613.793331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2 score</th>\n",
       "      <td>0.488422</td>\n",
       "      <td>0.338493</td>\n",
       "      <td>0.396179</td>\n",
       "      <td>0.493222</td>\n",
       "      <td>0.436958</td>\n",
       "      <td>-2.677995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           OLSRegression  LassoRegression  RidgeRegression  RandomForest  \\\n",
       "MSE score    3145.386692      4067.208772      3712.537141   3115.877072   \n",
       "R2 score        0.488422         0.338493         0.396179      0.493222   \n",
       "\n",
       "               XGBoost  NeuralNetwok  \n",
       "MSE score  3461.812012  22613.793331  \n",
       "R2 score      0.436958     -2.677995  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performance from initial attempt.\n",
    "initialMetrics = pd.DataFrame(metrics_Initial, \n",
    "                         index = [\"MSE score\", \"R2 score\", \"SNR\"],\n",
    "                         columns = [\"OLSRegression\", \"LassoRegression\", \"RidgeRegression\", \"RandomForest\", \"XGBoost\", \"NeuralNetwok\"])\n",
    "initialMetrics[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46712e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OLSRegression</th>\n",
       "      <th>LassoRegression</th>\n",
       "      <th>RidgeRegression</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>NeuralNetwok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MSE score</th>\n",
       "      <td>2992.335630</td>\n",
       "      <td>3004.095720</td>\n",
       "      <td>2997.229190</td>\n",
       "      <td>3269.982650</td>\n",
       "      <td>4195.118823</td>\n",
       "      <td>23927.527059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2 score</th>\n",
       "      <td>0.492439</td>\n",
       "      <td>0.461785</td>\n",
       "      <td>0.463474</td>\n",
       "      <td>0.414577</td>\n",
       "      <td>0.252512</td>\n",
       "      <td>-3.197962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNR</th>\n",
       "      <td>0.938803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           OLSRegression  LassoRegression  RidgeRegression  RandomForest  \\\n",
       "MSE score    2992.335630      3004.095720      2997.229190   3269.982650   \n",
       "R2 score        0.492439         0.461785         0.463474      0.414577   \n",
       "SNR             0.938803         0.000000         0.000000      0.000000   \n",
       "\n",
       "               XGBoost  NeuralNetwok  \n",
       "MSE score  4195.118823  23927.527059  \n",
       "R2 score      0.252512     -3.197962  \n",
       "SNR           0.000000      0.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Baseline performance from cross-validation\n",
    "\n",
    "cvMetricsFrame = pd.DataFrame(metrics_TestingCV, \n",
    "                         index = [\"MSE score\", \"R2 score\", \"SNR\"],\n",
    "                         columns = [\"OLSRegression\", \"LassoRegression\", \"RidgeRegression\", \"RandomForest\", \"XGBoost\", \"NeuralNetwok\"])\n",
    "cvMetricsFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfa4132f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OLSRegression</th>\n",
       "      <th>LassoRegression</th>\n",
       "      <th>RidgeRegression</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>NeuralNetwok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MSE improvement</th>\n",
       "      <td>-20.572591</td>\n",
       "      <td>-34.444533</td>\n",
       "      <td>-34.360725</td>\n",
       "      <td>-5.526038</td>\n",
       "      <td>-127.230615</td>\n",
       "      <td>45.348770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2 improvement</th>\n",
       "      <td>0.003388</td>\n",
       "      <td>0.006499</td>\n",
       "      <td>0.006681</td>\n",
       "      <td>-0.000821</td>\n",
       "      <td>0.013701</td>\n",
       "      <td>-0.015549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNR improvement</th>\n",
       "      <td>0.020186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 OLSRegression  LassoRegression  RidgeRegression  \\\n",
       "MSE improvement     -20.572591       -34.444533       -34.360725   \n",
       "R2 improvement        0.003388         0.006499         0.006681   \n",
       "SNR improvement       0.020186         0.000000         0.000000   \n",
       "\n",
       "                 RandomForest     XGBoost  NeuralNetwok  \n",
       "MSE improvement     -5.526038 -127.230615     45.348770  \n",
       "R2 improvement      -0.000821    0.013701     -0.015549  \n",
       "SNR improvement      0.000000    0.000000      0.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performance improvement from dropping 2 low importance features.\n",
    "#Note: +ve R2 and -ve MSE scores indicates positive increase. The reverse is a decrease in peformance with CV attempt as baseline.\n",
    "\n",
    "featuresDropdiff = metrics_ageS6_removed - metrics_TestingCV\n",
    "featuresDroppedMetricsFrame = pd.DataFrame((featuresDropdiff), \n",
    "                         index = [\"MSE improvement\", \"R2 improvement\", \"SNR improvement\"],\n",
    "                         columns = [\"OLSRegression\", \"LassoRegression\", \"RidgeRegression\", \"RandomForest\", \"XGBoost\", \"NeuralNetwok\"])\n",
    "featuresDroppedMetricsFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b3e744",
   "metadata": {},
   "source": [
    "#From table above:\n",
    "1. Dropping 2 low importance features, marginally improved model performance on the diabetes dataset; MSE scores of all the models decreased, except for the neural network model. XGBoost showed highest improvement with a decrease of 127.23 units.\n",
    "\n",
    "2. R2 scores also had marginal increase, except in the RandomForest and Neural netwok models. Again, the XGBoost model saw highest increase of about 0.014 units.\n",
    "\n",
    "2. The signal to noise ratio (snr) also improved. This probably indicates that low importance features and which also does not interact with other features, only increases noise rather than signal.\n",
    "\n",
    "Summary/Conclusion: With the general decrease in MSE, increased r2 and snr scores, though marginally, reduction of low importance features had positive influence on model performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4798eec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OLSRegression</th>\n",
       "      <th>LassoRegression</th>\n",
       "      <th>RidgeRegression</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>NeuralNetwok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MSE score</th>\n",
       "      <td>-42.160563</td>\n",
       "      <td>-34.426581</td>\n",
       "      <td>-35.501725</td>\n",
       "      <td>50.930922</td>\n",
       "      <td>-165.704907</td>\n",
       "      <td>63.107559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2 score</th>\n",
       "      <td>0.007111</td>\n",
       "      <td>0.006496</td>\n",
       "      <td>0.006883</td>\n",
       "      <td>-0.011117</td>\n",
       "      <td>0.018405</td>\n",
       "      <td>-0.099803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNR</th>\n",
       "      <td>-0.002689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           OLSRegression  LassoRegression  RidgeRegression  RandomForest  \\\n",
       "MSE score     -42.160563       -34.426581       -35.501725     50.930922   \n",
       "R2 score        0.007111         0.006496         0.006883     -0.011117   \n",
       "SNR            -0.002689         0.000000         0.000000      0.000000   \n",
       "\n",
       "              XGBoost  NeuralNetwok  \n",
       "MSE score -165.704907     63.107559  \n",
       "R2 score     0.018405     -0.099803  \n",
       "SNR          0.000000      0.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performance improvement from dropping 2 low importance features and adding 3 new inteaction features.\n",
    "\n",
    "fullModMetricDiff = metrics_mod_complete - metrics_TestingCV\n",
    "modCompleteMetricsFrame = pd.DataFrame((fullModMetricDiff), \n",
    "                         index = [\"MSE score\", \"R2 score\", \"SNR\"],\n",
    "                         columns = [\"OLSRegression\", \"LassoRegression\", \"RidgeRegression\", \"RandomForest\", \"XGBoost\", \"NeuralNetwok\"])\n",
    "modCompleteMetricsFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58429c19",
   "metadata": {},
   "source": [
    "#From table above:\n",
    "1. Dropping 2 low importance features and adding custom interaction features, also improved model performance on the diabetes dataset, though marginally. MSE scores of all the models decreased, except for the neural network and random forest model. XGBoost showed highest improvement with a decrease of about 167.70 units. \n",
    "\n",
    "2. R2 scores also had marginal increase, except in the RandomForest and Neural netwok models. Again, the XGBoost model saw highest increase of about 0.018 units.\n",
    "\n",
    "2. Here, signal to noise ratio (snr) dropped. Added interaction features appear to have added more noise than signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a116db0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OLSRegression</th>\n",
       "      <th>LassoRegression</th>\n",
       "      <th>RidgeRegression</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MSE score</th>\n",
       "      <td>-21.587972</td>\n",
       "      <td>0.017952</td>\n",
       "      <td>-1.141000</td>\n",
       "      <td>-38.474292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2 score</th>\n",
       "      <td>0.003722</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.004704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SNR</th>\n",
       "      <td>-0.022874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           OLSRegression  LassoRegression  RidgeRegression    XGBoost\n",
       "MSE score     -21.587972         0.017952        -1.141000 -38.474292\n",
       "R2 score        0.003722        -0.000003         0.000201   0.004704\n",
       "SNR            -0.022874         0.000000         0.000000   0.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#So the question now becomes did the complete modifications really yield positive improvement\n",
    "#or did the sub-step (low importance feature removal alone) yield better?\n",
    "\n",
    "#To determie this, we will subtract the featuresDroppedMetrics(sub-step metrics) from modCompleteMetrics(final metrics).\n",
    "#A -ve MSE, +ve r2 and +ve snr scores will mean that the complete modifications, yielded positive improvement.\n",
    "\n",
    "stepsComparisonMetrics = fullModMetricDiff - featuresDropdiff\n",
    "stepCompMetricsFrame = pd.DataFrame(stepsComparisonMetrics, \n",
    "                         index = [\"MSE score\", \"R2 score\", \"SNR\"],\n",
    "                         columns = [\"OLSRegression\", \"LassoRegression\", \"RidgeRegression\", \"RandomForest\", \"XGBoost\", \"NeuralNetwork\"])\n",
    "\n",
    "#To simplify comparisons, we will leave out  the models which by default have poor performances: RandomForest and NeuralNetwork.\n",
    "\n",
    "for model in stepCompMetricsFrame.columns:\n",
    "    if model == \"RandomForest\" or model == \"NeuralNetwork\":\n",
    "        stepCompMetricsFrame.drop(model, axis=1, inplace=True)\n",
    "stepCompMetricsFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583cc94a",
   "metadata": {},
   "source": [
    "From table above, 3 out of 4 models confirm that the complete modifications-for-improvement really yielded positive model peformance. Nevertheless, SNR and lasso regression had their highest scores from only low importance feature removal. \n",
    "\n",
    "Note: Model hyperparameters were not tuned. So this could be a major source of bias. \n",
    "\n",
    "Focus for further improvements:\n",
    "1. Tuning of model hyperparameters for better performance.\n",
    "2. Given smallness of sklearn's diabetes dataset, GAN or VAE could be used to augment dataset size."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10(alibi-env)",
   "language": "python",
   "name": "alibi-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
